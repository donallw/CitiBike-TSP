{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98961e78",
   "metadata": {},
   "source": [
    "# CitiBike TSP\n",
    "**Algorithms Group 50**\\\n",
    "Donal Lowsley-Williams \\\n",
    "Joan La Rosa \\\n",
    "Isaac Lichter \\\n",
    "Weidong Gao \n",
    "\n",
    "We will be conducting the traveling salesman problem on New York City citibike data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c5479",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Will we be implementing these algorithms by hand, so we just need libraries for data loading and export, matrix manipulation functions, and some data exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12119b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa2897",
   "metadata": {},
   "source": [
    "# The Data\n",
    "We will get the data from CitiBike's openly available [System Data](https://s3.amazonaws.com/tripdata/index.html). The data we are using was the most recent as of this notebook's creation date, and was published by CitiBike on [**Oct 4th 2021, 01:26:29 pm**](https://s3.amazonaws.com/tripdata/202109-citibike-tripdata.csv.zip). This is the data of all rides taken on the CitiBike system during the month of September 2021. However, the preprocessing should work for any selection of the data from the system data, since they all should follow the same structure. \n",
    "\n",
    "Please store the data in a folder named **\"Data\"** with the name **\"citibike-data.csv\"**, like so: **\"Data/citibike-data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "055d1a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\donal\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/citibike-data.csv',\n",
    "                 parse_dates=['started_at','ended_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d75c5",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "In order to preprocess the data, \n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "First lets take a look at the length of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "64717c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280221"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec2b40",
   "metadata": {},
   "source": [
    "Now, lets see what the column was that caused data type issues. We can see from the error above that it was column 7, which corresponds to the `end_station_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "07b559ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end_station_id'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eed57a",
   "metadata": {},
   "source": [
    "In the data, we can see by looking at the csv file that these values are typically float values, so we can cast them to a numeric value. We set any values that can't be cast to a numeric value to `NaN` by setting `errors='coerce'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dbdd6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['end_station_id'] = df['end_station_id'].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6632ff",
   "metadata": {},
   "source": [
    "We drop all null values. (those with `NaN`) This includes not just those with a faulty `end_station_id` value but those with errors elsewhere. We want to use only entries with full and complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1d7eff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406494df",
   "metadata": {},
   "source": [
    "We can see that we dropped approx. 15K entries that had data issues or invalid end stations. This is negligible in the grand scheme of the project, given that we have about 3.2M entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "557e6d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3264732"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded74a03",
   "metadata": {},
   "source": [
    "Let's take a peek at our data and its types. We can see that many use the dtype object, which pandas uses to refer to strings with varying length. We can leave this be. We have a couple date items, which we set when reading the csv file. The remaining data is all float data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "148d27e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3264732 entries, 0 to 3280220\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   ride_id             object        \n",
      " 1   rideable_type       object        \n",
      " 2   started_at          datetime64[ns]\n",
      " 3   ended_at            datetime64[ns]\n",
      " 4   start_station_name  object        \n",
      " 5   start_station_id    float64       \n",
      " 6   end_station_name    object        \n",
      " 7   end_station_id      float64       \n",
      " 8   start_lat           float64       \n",
      " 9   start_lng           float64       \n",
      " 10  end_lat             float64       \n",
      " 11  end_lng             float64       \n",
      " 12  member_casual       object        \n",
      "dtypes: datetime64[ns](2), float64(6), object(5)\n",
      "memory usage: 348.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f31efe",
   "metadata": {},
   "source": [
    "Let's conduct a quick sanity check to ensure the data is properly cleaned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "25da64bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7141.07, 5175.08, 3651.04, ..., 8290.01, 4203.04, 8285.11])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['start_station_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "29fe5813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start station id uniques:  1488\n",
      "start station name uniques:  1493\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('start station id uniques: ',len(df['start_station_id'].unique()))\n",
    "print('start station name uniques: ',len(df['start_station_name'].unique()))\n",
    "print(len(df['start_station_id'].unique()) == len(df['start_station_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ee71334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end station id uniques:  1488\n",
      "end station name uniques:  1493\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('end station id uniques: ',len(df['end_station_id'].unique()))\n",
    "print('end station name uniques: ',len(df['end_station_name'].unique()))\n",
    "print(len(df['end_station_id'].unique()) == len(df['end_station_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382ea80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b639717",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Now we need to include some additional features in order to effectively run our algorithms. Specifically, we need to create a distance measure between each station, and store this in a distance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d75d93e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['end_station_id'].unique()) == len(df['end_station_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "58d536a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_traveled'] = ((df['ended_at'] - df['started_at']) / np.timedelta64(1, 's')).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb2ce7",
   "metadata": {},
   "source": [
    "# The Algorithms\n",
    "Now that we have pulled and preprocessed our data, we can begin to test various algorithms against it. We will test the following algorithms:\n",
    "\n",
    "**Greedy**\n",
    "- Nearest Neighbor\n",
    "- Farthest First Traversal\n",
    "\n",
    "**?????**\n",
    "- Christofides Algorithm \n",
    "\n",
    "**K-opt Heuristic Algorithms**\n",
    "- 2-OPT\n",
    "- 3-OPT\n",
    "- Lin-Kernighan Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a154e5",
   "metadata": {},
   "source": [
    "## Greedy Algorithms\n",
    "First, we will examine various greedy algorithms and their effectiveness on the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a0841",
   "metadata": {},
   "source": [
    "### Nearest Neighbor\n",
    "\n",
    "The nearest neighbor algorithm is very simple and simply starts at a random node (or station in our example) and continues to visit unvisited nodes that are as close to the last visited node as possible .\n",
    "\n",
    "**Psuedocode:** \\\n",
    "These are the steps of the algorithm:\n",
    "\n",
    "    Initialize all vertices as unvisited.\n",
    "    Select an arbitrary vertex, set it as the current vertex u. Mark u as visited.\n",
    "    Find out the shortest edge connecting the current vertex u and an unvisited vertex v.\n",
    "    Set v as the current vertex u. Mark v as visited.\n",
    "    If all the vertices in the domain are visited, then terminate. Else, go to step 3.\n",
    "\n",
    "The sequence of the visited vertices is the output of the algorithm. \n",
    "\n",
    "**Time complexity:** Worst Case O(N^2)\n",
    "\n",
    "**Space complexity:** Worst Case O(N)\n",
    "\n",
    "[Source (wikipedia)](https://en.wikipedia.org/wiki/Nearest_neighbour_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41454baa",
   "metadata": {},
   "source": [
    "### Farthest-First Traversal\n",
    "\n",
    "**PseudoCode:**\\\n",
    "The farthest-first traversal of a finite point set may be computed by a greedy algorithm that maintains the distance of each point from the previously selected points, performing the following steps:[3]\n",
    "\n",
    "    Initialize the sequence of selected points to the empty sequence, and the distances of each point to the selected points to infinity.\n",
    "    While not all points have been selected, repeat the following steps:\n",
    "        Scan the list of not-yet-selected points to find a point p that has maximum distance from the selected points.\n",
    "        Remove p from the not-yet-selected points and add it to the end of the sequence of selected points.\n",
    "        For each remaining not-yet-selected point q, replace the distance stored for q by the minimum of its old value and the distance from p to q.\n",
    "\n",
    "**Time complexity:** Worst Case O(N^2)\n",
    "\n",
    "**Space complexity:** Worst Case O(N)\n",
    "\n",
    "[Source (wikipedia)](https://en.wikipedia.org/wiki/Farthest-first_traversal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3c7378fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farthest-First Traversal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
